{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Analyze motion data from SenseHAT to detect figures\n\nWith the TjBot based on Raspberry Pi the motion sensor data (acc, gyro, compass, ..) from the SenseHAT will be pushed through the IoT Foundation via MQTT into a cloudant DB. With this python notebook you will be able to collect this data and create some visualisations.\n\nWith this python notebook you will be able to \n\n* collect this data and create some visualisations\n* and to train a support vector classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Install the necessary python libraries missing by default", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# install missing library for cloudant\n!pip install cloudant"
        }, 
        {
            "source": "## Get the credentials to access the cloudant DB\n\nUse the existing connection document (CloudandDB) and push \"insert code\" rename it to credentials.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "## Import the cloudant client ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from cloudant.client import Cloudant\nfrom cloudant.result import Result, ResultByKey\nfrom cloudant.query import Query\n\nclient = Cloudant(credentials['username'], credentials['password'], \n                  url=credentials['custom_url'], connect=True)"
        }, 
        {
            "source": "### Select the database", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "database  = client['sensehat_motion']"
        }, 
        {
            "source": "## Construct a Query for Motion objects\n\nmaybe query as a sorted list but needs index in the DB: \n    sort=['payload.d.device', 'payload.d.userid','payload.d.figure','payload.d.motionset', 'payload.d.date']", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Select statement for document selection\n# filter on one the date element to collect the subset\nselector = {\n    '_id':{'$gt': 0},\n    'payload.d.motionset': {\n        '$gte': '2018-12-16T08:00',  # $gte: greater than or equal\n        '$lt': '2018-12-17T00:00'},  # $lte: less than or equal\n}\n\n# Selected fields of the document\nfields = [\n    'payload.d.acceleration',\n    'payload.d.gyroscope',\n    'payload.d.orientation',\n    'payload.d.compass',\n    'payload.d.device',    \n    'payload.d.userid',\n    'payload.d.figure',\n    'payload.d.motionset',\n    'payload.d.timestamp',\n    'payload.d.date']\n\n# Create the query and get a handler\nmotion_query = Query (\n    database,\n    selector=selector, \n    fields=fields\n)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# show 5 elements from the cloudantDB\nfor doc in motion_query(limit=5) ['docs']:\n    print(doc)"
        }, 
        {
            "source": "# Using pandas for the data processing", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pandas as pd\nfrom pandas import date_range, to_datetime\nfrom pandas.io.json import json_normalize\nfrom pandas import Timestamp, DataFrame, Series, Timedelta, concat"
        }, 
        {
            "source": "## Store the data in an array as a table\n\nAlso rename the columns for better reading afterwards", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# get all json-objects (documents) out of the query \njson_docs = motion_query()['docs']\n\n# normalize into a dataframe\ndf = json_normalize(json_docs)\n\ndf.head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# rename all columns into clear names\ndf = df.rename(\n    columns= {\n    'payload.d.acceleration.x' : 'acc_x',\n    'payload.d.acceleration.y' : 'acc_y',\n    'payload.d.acceleration.z' : 'acc_z',\n    'payload.d.gyroscope.x' : 'gyro_x',\n    'payload.d.gyroscope.y' : 'gyro_y',\n    'payload.d.gyroscope.z' : 'gyro_z',\n    'payload.d.orientation.roll' : 'roll',\n    'payload.d.orientation.pitch' : 'pitch',\n    'payload.d.orientation.yaw' : 'yaw',\n    'payload.d.compass':'compass',\n    'payload.d.device':'device',    \n    'payload.d.userid':'userid',\n    'payload.d.figure':'figure',\n    'payload.d.motionset':'motionset',\n    'payload.d.timestamp':'timestamp',\n    'payload.d.date':'date'        \n    }\n)\ndf.head()"
        }, 
        {
            "source": "## Reorganize the array and sort", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# get the columns names\ncols = df.columns.tolist()\ncols"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# reorder the columns from the array\ncols = [\n    'device',\n    'userid',    \n    'figure',\n    'motionset',\n    'date',\n    'timestamp',\n    'acc_x',\n    'acc_y',\n    'acc_z',\n    'gyro_x',\n    'gyro_y',\n    'gyro_z',\n    'pitch',\n    'roll',\n    'yaw',\n    'compass'\n]\n\ndf = df[cols]\ndf.head()"
        }, 
        {
            "source": "### change the values to its datatype and sort the values ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df['date'] = to_datetime(df.date)\ndf['motionset'] = to_datetime(df.motionset)\ndf['figure'] = [str(l) for l in df.figure]\ndf = df.set_index('date').sort_index()\ndf = df.sort_values(['device','userid','figure','motionset'])\ndf.head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# show the end of the dataframe\ndf.tail()"
        }, 
        {
            "source": "# Organize all figures out of the training set into an directory", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from collections import defaultdict"
        }, 
        {
            "source": "## store figures & motions into a directory \n\ncreate a loop of all figures and store each motionset into a dataframe (appand into an array on each figure)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# loop only for 5 motionsets for demonstration only\nfor (figure, motionset_id), motionset_data in list(df.groupby(['figure', 'motionset']))[:5]:\n    print(figure, motionset_id, len(motionset_data), type(motionset_data))"
        }, 
        {
            "source": "### Usage of special directories", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# classical directories give a failure if the element doesn't exist\nd={}\n# d['a']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# special directory which allows asking elements without failure when not exists\nd = defaultdict(list)\nd['a']"
        }, 
        {
            "source": "### store all motions into motionset\n\nmotionset will be the overall array of every figures", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# using groupby function on the motions dataset\nmotionset = defaultdict(list)\nfor (figure, _), data in df.groupby(['figure', 'motionset']):\n    motionset[figure].append(data)\n\n# give the amount of each figure and its stored motions\nfor figure, datasets in sorted(motionset.items()):\n    print (\"'{}' : {} recorded motions\".format(figure, len(datasets)))"
        }, 
        {
            "source": "# Plot examples to gain insights of the motionsets", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import matplotlib.pyplot as plt"
        }, 
        {
            "source": "## Sample of one figure", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# first array is the figure, second is one motionset \nmotionset['1'][-1][['acc_x', 'acc_y', 'acc_z']].plot(grid=True, figsize=(15,5));"
        }, 
        {
            "source": "### Sample Plot on each figure", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# get all figures and plot one figure (the last motion for each figure: -1)\nfor k in motionset.keys():\n    motionset[k][-1][['acc_x', 'acc_y', 'acc_z']].plot(title=k, grid=True, figsize=(15,5))"
        }, 
        {
            "source": "### Sample Plot on each figure multiple motionsets\n\nto get insights into the difference of each motionset on the same figure", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "#  print up to 3 on one figure to compare its behavior\n# get all the possible figures\nfor fig in sorted(motionset.keys()):\n\n    # max 2 plots\n    l = min(2, len(motionset[fig]))\n\n    # print max l on each figure\n    for i in range(l):\n        motionset[fig][i][['acc_x', 'acc_y', 'acc_z']].plot(title='Figure:' + fig + ' Num:' + str(i), grid=True, figsize=(5,3))\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Subplots are organized in a Rows x Cols Grid\nfigures = sorted(motionset.keys())\nTot = len(figures)\nCols = 2\n\n# Compute Rows required\nRows = Tot // Cols \nRows += Tot % Cols\n\nprint('Total:' + str(Tot) + ' Rows: ' + str(Rows) + ' Cols:' + str(Cols))\n\n# Create a Position index\nPosition = range(1,Tot + 1)\n\n# Create main figure\nfig = plt.figure(1)\nfig.set_size_inches(20,25)\n\n# Create a figure on each sample motionset\ni = 0 \nfor k in figures:    \n    # add every single subplot to the figure with a for loop\n    ax = fig.add_subplot(Rows,Cols,Position[i])\n    df = motionset[k][-2]\n    ax.plot(df.index, df[['acc_x']], label='Accel-x')\n    ax.plot(df.index, df[['acc_y']], label='Accel-y')\n    ax.plot(df.index, df[['acc_z']], label='Accel-z')\n\n    ax.set_title('Sample of figure: '+ k)\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n    ax.grid(True)\n    i+=1\n    \nplt.show()"
        }, 
        {
            "source": "# Build a training data set", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "* The idea is to transform all figures into equally long montions.\n* Then we can pass them into a classical machine learning algorithms like a support vecotor classifier.\n* We will achieve this by interpolating along the time axis.\n* We concentrate on the accelleration features first\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "features = ['acc_x', 'acc_y', 'acc_z']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df = motionset['0'][2][features + ['timestamp']]\ndf = df.set_index('timestamp')\ndf.index = df.index - df.index.min()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "title=\"#points={:g}\".format(len(df))\ndf.plot(style=['d--', 'd--', 'd--', ], grid=True, figsize=(15,5), title=title);"
        }, 
        {
            "source": "#### Make a regular time index from minimum to maximum with $n$ points\n\n* Use numpy's linear interpolation function interp", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import numpy as np"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "t1, t2 = df.index.min(), df.index.max()\nnew_index = np.linspace(t1, t2, 25)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "np.interp(new_index, df.index, df.values[:,1])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ip = DataFrame(\n    data = dict((col,np.interp(new_index, df.index, df[col].values)) for col in df),\n    index = new_index\n)\nip"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "title=\"original data (n={:g})\".format(len(df))\ndf.plot(style=['d--', 'd--', 'd--', ], grid=True, figsize=(15,3), title=title);\n\ntitle=\"interpolated data (n={:g})\".format(len(ip))\nip.plot(style=['.-', '.-', '.-', ], grid=True, figsize=(15,3), title=title);"
        }, 
        {
            "source": "### Combine everything into a function to make a normalized time series for each figure motion", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def make_normalized_data(df, w=25):\n\n    df = df.set_index('timestamp')\n    df.index = (df.index - df.index.min())\n    \n    t1, t2 = df.index.min(), df.index.max()\n    \n    new_index = np.linspace(t1, t2, w)\n\n    interp = DataFrame(\n        data = dict((col, np.interp(new_index, df.index, df[col].values)) for col in df),\n        index = new_index\n    )\n    return interp"
        }, 
        {
            "source": "## Data cleaning", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Each recored motion shall have enough accelaration values", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df = motionset['0'][0][features + ['timestamp']]\nip = make_normalized_data(df)\nip.plot(grid=True, figsize=(15,5), title=title);"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ip.var().sum()"
        }, 
        {
            "source": "#### Each recorded motion shall have a proper duration (i.e. prober number of messages)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pandas import Series\nimport numpy as np\n\n# make a list of observed length\ncounts = [len(df) for df in motionset['1']]\nprint(counts)\n\n# compute a robust estimate of the typical length\ncounts = Series(counts)\nq25 = np.floor(counts.quantile(0.25))\nq75 = np.ceil(counts.quantile(0.75))\nprint(\"quantiles:\", q25, q75)\n\nlower = q25 - 2*(q75-q25)\nupper = q75 + 2*(q75-q25)\nprint(\"bounds:\", lower, upper)"
        }, 
        {
            "source": "#### Padas detour: A Dataframe can easily be reshape into a vector", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ip.values"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ip.values.reshape(-1)"
        }, 
        {
            "source": "##### Note\n\nThe `ip.values` array is row-major. That means, that `ip.values.reshape(-1)` yields a vector where the first elements are the first *row* of `ip.values`, then the following rows are concatenated.\n\nMore general. If $A=[a_{ij}]$ for $i = 1, \\ldots, m$ and $j=1, \\ldots n$ and A is row-major `b = A.rehsape(-1)` will yield the vector $b = [a_{1,1}, \\ldots, a_{1,n}, a_{2,1}, \\ldots, a_{2,n}, \\ldots, a_{m,1}, \\ldots, a_{m,n}]$ ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Build a list of relevant feature vectors and labels out of motion set", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "features = ['acc_x' ,'acc_y', 'acc_z'] # + ['gyro_x', 'gyro_y', 'gyro_z']\n\n# vectors will contain all relevant feature vectors\nvectors = []\n\n# the corresponfing labels\nlabels = []\n\n# loop over all motion sets\nfor figure, datasets in motionset.items():\n    \n    # comput robus upper and lower bounds on length\n    counts = Series([len(df) for df in datasets])\n    q25 = np.floor(counts.quantile(0.25))\n    q75 = np.ceil(counts.quantile(0.75))\n    lower = q25 - 2*(q75-q25)\n    upper = q75 + 2*(q75-q25)\n    \n    # for each data set ...\n    for df in datasets:\n        # ... check its length\n        if lower <= len(df) <= upper:\n            # if long enough compute its normalized version\n            ip = make_normalized_data(df[features + ['timestamp']])\n            \n            # if it has sufficient variance add it as a training example\n            variance =  ip.var().sum()\n            if variance > 0.01:\n                vectors.append(ip.values.reshape(-1))\n                labels.append(figure)\n            else:\n                print(\"Skipping motion for '{}': total variance {} to small.\".format(figure, variance))\n        else:\n            print(\"Skipping motion for '{}': length {} not in range [{}, {}]\".format(figure, len(df), lower, upper))"
        }, 
        {
            "source": "### Convert to design matrix X and label vector Y", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X = DataFrame(vectors)\nY = Series(labels)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X.describe()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "Y.describe()"
        }, 
        {
            "source": "# Finally apply machine learning to build a motion classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Directly apply a support vector classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.svm import SVC"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "svm = SVC()\nsvm.fit(X,Y)"
        }, 
        {
            "source": "### Evaluate what has been learnt", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_pred = svm.predict(X)"
        }, 
        {
            "source": "#### Confusion Matrix", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.metrics import confusion_matrix\n\nlabels=sorted(motionset.keys())\nC = confusion_matrix(Y, y_pred, labels=labels)\nC"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# format it as a DataFrame (for nice visual)\nC = DataFrame(C, columns=labels, index=labels)\nC.index.name='true'\nC.columns.name='pred'\nC"
        }, 
        {
            "source": "#### Recall / Precision / F1\n\n* Recall ($r$): Percentage of class which was classified correctly\n* Precision ($p$): Percentage of predictions of a class which are predicted correctly\n* F1: $2\\frac{r \\cdot p}{r + p}$ ... $0 \\le F1 \\le 1$", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.metrics.classification import f1_score, precision_score, recall_score, accuracy_score"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "accuracy_score(Y, y_pred)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "recall_score(Y, y_pred, average='weighted')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "precision_score(Y, y_pred, average='weighted')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "f1_score(Y, y_pred, average='weighted')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.metrics.classification import classification_report, f1_score, precision_score, recall_score\nprint(classification_report(Y, y_pred))"
        }, 
        {
            "source": "##### Detailed look on wrong classification", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wrong = np.where(y_pred != Y)[0]\nDataFrame(\n    data=[[i, Y[i], y_pred[i]] for i in wrong],\n    columns=['Example', 'True', 'Predicted']\n)"
        }, 
        {
            "source": "## Make better data preparation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Make all features 'similar' (standardization)\n\n* subtract mean\n* divide by standard deviation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "plt.plot(X.mean());\nplt.grid(True);"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "plt.plot(X.std());\nplt.grid(True);"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "scaler = StandardScaler()\nscaler.fit(X)\nX0 = scaler.transform(X)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "plt.plot(X0.mean(axis=0));\nplt.grid(True);"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "plt.plot(X0.std(axis=0));\nplt.grid(True);"
        }, 
        {
            "source": "## Combine the scaler and a classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model = Pipeline([\n    ('scale', StandardScaler()),\n    ('svc', SVC()),\n])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.fit(X,Y)\ny_pred = model.predict(X)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "labels=sorted(motionset.keys())\nC = confusion_matrix(Y, y_pred, labels=labels)\nC"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_pred_train = model.predict(X)\nprint(classification_report(Y, y_pred_train))"
        }, 
        {
            "source": "### Assess the generalization capability by crossvalidation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.model_selection import cross_validate"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cv = cross_validate(model, X, Y, cv=10, return_train_score=False)\nDataFrame(data=cv)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.model_selection import cross_val_predict"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_pred_cv = cross_val_predict(model, X, Y, cv=10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wrong = np.where(y_pred_cv != Y)[0]\nDataFrame(\n    data=[[i, Y[i], y_pred_cv[i]] for i in wrong],\n    columns=['Example', 'True', 'Predicted']\n)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(classification_report(Y, y_pred_cv))"
        }, 
        {
            "source": "### Let's try to improve the classifier", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model = Pipeline([\n    ('scale', StandardScaler()),\n    ('svc', SVC(kernel='rbf')),\n])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_pred_cv = cross_val_predict(model, X, Y, cv=10)\nprint(classification_report(Y, y_pred_cv))"
        }, 
        {
            "source": "### Automatic meta parameter search", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.model_selection import GridSearchCV"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "gamma0 = 1.0 / (X.shape[1] * X.std().std())\n\nsvm_cv = GridSearchCV(\n            estimator = SVC(kernel='rbf'),\n            param_grid = [\n                # variations with the RBF kernel\n                dict(\n                    kernel=['rbf'],\n                    C=[1, 0.1, 0.01],\n                    gamma=np.array([1/10, 1/5, 1/2, 1.0, 2, 4])*gamma0\n                ),\n                # variations with a linear kernel\n                dict(\n                    kernel=['linear'],\n                    C=[1, 0.1, 0.01]\n                )\n            ],\n            cv = 10,\n            iid=True,\n            verbose = 1\n        )\n\nmodel = Pipeline([\n    ('scale', StandardScaler()),\n    ('svc', svm_cv),\n])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.fit(X,Y)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.named_steps['svc'].best_params_ "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_pred_cv = cross_val_predict(model, X, Y, cv=10)\nprint(classification_report(Y, y_pred_cv))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wrong = np.where(y_pred_cv != Y)[0]\nDataFrame(\n    data=[[i, Y[i], y_pred_cv[i]] for i in wrong],\n    columns=['Example', 'True', 'Predicted']\n)"
        }, 
        {
            "source": "# Train final model and deploy to Watson Machine Learning (WML)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Prerequisits\n\nFirst one has to initialize a machine learning model service and ad credetials for this service", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Install and import machine learning client library and copy the credentials in a hidden cell", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install watson-machine-learning-client --upgrade"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "### Instantiate a client", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wml_client = WatsonMachineLearningAPIClient(wml_credentials)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import json\n\ninstance_details = wml_client.service_instance.get_details()\nprint(json.dumps(instance_details, indent=2))"
        }, 
        {
            "source": "#### Build final model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "final = model = Pipeline([\n    ('scale', StandardScaler()),\n    ('svc', SVC(kernel='rbf')),\n])\n\ny_pred_cv = cross_val_predict(final, X, Y, cv=10)\nprint(classification_report(Y, y_pred_cv))\n\nfinal.fit(X,Y)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model_props = {\n    wml_client.repository.ModelMetaNames.AUTHOR_NAME: \"Thomas Natschl\u00e4ger\", \n    wml_client.repository.ModelMetaNames.AUTHOR_EMAIL: \"thomas.natschlaeger@gmail.com\",\n    wml_client.repository.ModelMetaNames.NAME: \"Motion based digit classification\"\n}\nmodel_props"
        }, 
        {
            "source": "#### Publishing the model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "published_model = wml_client.repository.store_model(model=final, meta_props=model_props, training_data=X, training_target=Y)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wml_client.repository.list_models()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "published_model_uid = wml_client.repository.get_model_uid(published_model)\nmodel_details = wml_client.repository.get_details(published_model_uid)\nprint(json.dumps(model_details, indent=2))"
        }, 
        {
            "source": "#### Creating a deployment (i.e. the callable WEB service)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "created_deployment = wml_client.deployments.create(published_model_uid, \"Deployment digit classifier\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(json.dumps(created_deployment, indent=2))"
        }, 
        {
            "source": "# Use the deployed model via the client", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model_scoring_url = wml_client.deployments.get_scoring_url( created_deployment )\nmodel_scoring_url"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "wml_client.deployments.score( model_scoring_url, { \"values\" : [list(X.iloc[1,:])] } )"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "Y.iloc[1]"
        }, 
        {
            "source": "# Create a function which does the preprocessing and calls the deployed model\n\nFor more details see https://dataplatform.cloud.ibm.com/docs/content/analyze-data/ml-deploy-functions.html", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "parms = { \n    'wml_credentials' : wml_credentials,\n    'model_scoring_url' : model_scoring_url,\n    'n_interp': 25,\n    'min_number_of_events': 6\n}\n\ndef digit_classification( parms=parms ):\n    \n    def make_feature_matrix(values):\n        \"\"\"\n        values is the array of motion events\n        \"\"\"\n        import numpy as np\n        # parameter:\n        #   w ... number of points for interpolation. Must be the same as during learning the model\n        w = parms['n_interp']\n\n        # time stamps of recorded data in form of numpy vector\n        t_rec = np.array([e['timestamp'] for e in values])\n\n        # accelaration data in form of a numpy array of shape (len(payload),3)\n        a_rec = np.array([\n            [e['acceleration'][col] for col in ('x', 'y', 'z')] for e in values\n        ])\n\n        # make a regular linear space from the begining to the end\n        t_int = np.linspace(t_rec[0], t_rec[-1], w)\n\n        # now interpolate the x, y, and z coordinate\n        a_int = np.zeros((w, 3))\n        for j in (0,1,2):\n            a_int[:,j] = np.interp(t_int, t_rec, a_rec[:,j])\n\n        return a_int\n        \n    def score(payload):\n            \n        try:\n            \n            # we need WML client to be able to call the previously deployed SVC model\n            from watson_machine_learning_client import WatsonMachineLearningAPIClient\n            client = WatsonMachineLearningAPIClient( parms[\"wml_credentials\"] )\n\n            # values is the array of motion events\n            values = payload['values']\n            \n            # if we have only a very small number of events we return \"<to-short>\"\n            if len(values) < parms['min_number_of_events']:\n                 return {\"figure\" : \"<to-short>\"}\n            \n            # convert the JSON data structure into a numpy array\n            data = make_feature_matrix(values)\n            \n            # compute the sum of the variances of the x, y, z acceleration signals\n            variance = data.var(axis=0).sum()\n            \n            # if the variance is to low there was probably no motion and we return \"<no-motion>\"\"\n            if variance < 0.01:\n                return {\"figure\" : \"<no-motion>\"}\n            \n            \n            # the depoyed model requires a scoring_payload with a field names 'values'.\n            # where the values must be a list of feature vectors. Each feature vector\n            # has to have the required dimension (75 in our case) and must be a plain\n            # python list (a numpy array does not work bcs it is not JSON serializable).\n            scoring_payload = {'values': [list(data.reshape(-1))]}\n            \n            # now we call the model via the REST API endpoint at the scoring url\n            model_result = client.deployments.score( parms[\"model_scoring_url\"], scoring_payload )\n            \n            # the result is a dictionaory where in the field 'values' the predictions are stored\n            # the [0][0] is required as values is a list of predictions (one for each feature vector in\n            # the scoring payload) and each prediction is a vector. In our case each such vector only has\n            # one entry (the classification) but it may be that there are multiple outputs (e.g. for a neural network)\n            digit_class  = model_result[\"values\"][0][0]\n            \n            # return the class of the digit/motion\n            return { \"figure\" : digit_class }\n            \n        except Exception as e:\n            return { \"error\" : repr( e ) }\n\n    return score"
        }, 
        {
            "source": "### Test the function with some data from ClaudantDB\n\n**NOTE: You have to adapt the selector for your database. In particulare the `payload.d.motionset` part.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# select some motion sets for a particual figure\nselector = {\n    '_id':{'$gt': 0},\n    'payload.d.motionset': {\n        '$gte': '2018-12-16T08:00',  # $gte: greater than or equal\n        '$lt': '2018-12-17T00:00' # $lte: less than or equal\n    },\n    'payload.d.figure': '4',\n}\n\n# Create the query ...\nfigure_query = Query(database, selector=selector, fields=fields)\n\n# ... and get all motion sets\nmotionsets = sorted(set(e['payload']['d']['motionset'] for e in figure_query()['docs']))\n\n# now pick one motionset and build a new query for the particular motionset\nselector['payload.d.motionset'] = motionsets[1]\nfigure_query = Query(database, selector=selector, fields=fields)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# make a sorted array of events and remove the payload.d prefix\nvalues = sorted([e['payload']['d'] for e in figure_query()['docs']], key=lambda e: e['timestamp'])\nvalues[:2]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "payload = {\n    'values': values\n}"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# now do the digit classification\ndigit_classification()(payload)"
        }, 
        {
            "source": "# Store and deploy the function\n\nBefore you can deploy the function, you must store the function in your Watson Machine Learning repository.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#\n# Store the deployable function in your Watson Machine Learning repository\n#\nmeta_props = {\n    wml_client.repository.FunctionMetaNames.NAME : 'Deployable Digit Classification'\n}\nfunction_details = wml_client.repository.store_function(meta_props=meta_props, function=digit_classification)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#\n# Deploy the stored function\n#\nartifact_uid = function_details[\"metadata\"][\"guid\"]\nfunction_deployment_details =wml_client.deployments.create(artifact_uid=artifact_uid, name=\"Digit Classification with preprocessing\")"
        }, 
        {
            "source": "# Test the deployed function\n\nYou can use \n\n 1. the Watson Machine Learning Python client or \n \n 2. REST API\n\nto send data to your function deployment for processing in exactly the same way you send data to model deployments for processing.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Get the endpoint URL of the function deployment just created\nfunction_deployment_endpoint_url = wml_client.deployments.get_scoring_url( function_deployment_details )\nfunction_deployment_endpoint_url"
        }, 
        {
            "source": "#### 1.) Watson Machine Learning Python client", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "result = wml_client.deployments.score( function_deployment_endpoint_url, payload )\nprint( result )"
        }, 
        {
            "source": "### 2. Watson Machine Learning REST API\n\nThis is actually the way which is then used at the Raspi using two HTTP request nodes.\n\n1. You get an access token from your WML instance using username and password\n2. Use this access toke in the next request where the scoring payload is sent to the function endpoint (function_deployment_endpoint_url)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import requests\n\n# Get a bearer token\nurl = wml_credentials[\"url\"] + \"/v3/identity/token\"\nresponse = requests.get( url, auth=( wml_credentials[\"username\"], wml_credentials[\"password\"] ) )\nmltoken = json.loads( response.text )[\"token\"]\n\n# Send sample canvas data to function deployment for processing\nheader = { 'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken }\nresponse = requests.post( function_deployment_endpoint_url, json=payload, headers=header )\nprint ( response.text )"
        }, 
        {
            "source": "# Now its time to go to Raspi and ... \n\n... implement the call to the WEB service access to the function `digit_classification` in Node.RED.\nSome remarks:\n\n* In the HTTP request node \"Get Token\" you have to use the following url `wml_credentials[\"url\"] + \"/v3/identity/token\"` (see result of cell below) and the user and password from wml_credentials\n* In the HTTP request node \"Classification Request\" you have to set msg.url to the value of `function_deployment_endpoint_url` (see a few cells above)\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wml_credentials[\"url\"] + \"/v3/identity/token\""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}